---
title: "Einf√ºhrung in R & RStudio ‚Äì Tag 2"
subtitle: "Fehlende Werte, Umkodieren & Workflows"
format:
  html:
    toc: true
    toc-title: "Tag 2 ‚Äì Inhalte"
    toc-location: left
    toc-depth: 2

    
sidebar: workshop1
---

Willkommen zur√ºck üëã  
Wir starten mit einem kurzen Recap von Tag 1 und kl√§ren offene Fragen.

# Recap - Tag 1

Wir haben im ersten Teil des Workshops gelernt, wie RStudio aufgebaut ist und funktioniert. Wir kennen nun die wichtigsten Grundlagen und k√∂nnen diese heute weiter **vertiefen und festigen**.

::: callout-tip
# **Recap-Fragen**
- Was ist ein Data Frame?
- Was macht `select()` vs. `filter()`?
- Wof√ºr nutzen wir Pipes (`|>`)?
:::

::: callout-note
# **Merksatz**

R ist eine **Programmiersprache** ‚Äì und wie jede Sprache lernt man sie durch **regelm√§√üige Nutzung**.

Fehler zu machen ist v√∂llig normal (auch wenn es manchmal frustrierend ist).  
F√ºr fast jedes Problem gibt es **eine L√∂sung, eine Erkl√§rung oder ein Paket** üòä
:::

___

# Umkodieren

In der Datenanalyse arbeiten wir h√§ufig mit Variablen, deren Werte **nicht direkt so vorliegen**, wie wir sie f√ºr eine Auswertung ben√∂tigen.

**Umkodieren** bedeutet, Werte oder Kategorien gezielt zu ver√§ndern oder neu zusammenzufassen, damit Variablen
- **inhaltlich korrekt** interpretiert werden k√∂nnen und
- **f√ºr Analysen** (z. B. Gruppenvergleiche, Skalenbildung) besser nutzbar sind.

Beim Umkodieren k√∂nnen zum Beispiel:

- Kategorien zusammengefasst werden  
  (z. B. mehrere Bildungsabschl√ºsse ‚Üí ‚Äûniedrig / mittel / hoch‚Äú)
- Werte umgedreht werden  
  (z. B. hohe Werte = geringe Zustimmung)
- neue Variablen aus bestehenden gebildet werden  
  (z. B. Summen- oder Skalenwerte) **‚Üí** das kennen wir schon!

::: callout-tip
# **Warum ist Umkodieren wichtig?**

Rohdaten sind selten sofort ‚Äûanalysefertig‚Äú. Durch Umkodieren stellen wir sicher, dass unsere Variablen **inhaltlich korrekt** interpretiert und **vergleichbar** ausgewertet werden k√∂nnen. Umkodierung ist daher ein wichtiger **Bestandteil der Datenaufbereitung** und **wichtig** f√ºr die sp√§teren Analysen!
:::

Im Folgenden sehen wir typische Beispiele f√ºr Umkodierungen und setzen sie direkt mit R um.

## Umkodieren invertierter Items

In Frageb√∂gen kommen h√§ufig invertierte Items vor. Das bedeutet: Hohe Werte dr√ºcken geringe Zustimmung aus ‚Äì oder umgekehrt.

Damit alle Items in dieselbe Richtung zeigen, m√ºssen invertierte Items umkodiert werden.

### Beispiel 

Die Items `hs04` bis `hs07 und hs09` Fragen die mentale Gesundheit in den letzten vier Wochen ab:

|**Variable**|**Inhalt**|**Skalierung**|
|----|----|----|
|hs04|"Hetze, unter Zeitdruck"| 1 = "Immer" bis 5 = "Nie"|
|hs05|"Niedergeschlage"| 1 = "Immer" bis 5 = "Nie"|
|hs06|"Ruhig, Ausgeglichen"| 1 = "Immer" bis 5 = "Nie"|
|hs07|"Jede menge Energie"| 1 = "Immer" bis 5 = "Nie"|
|hs09|"Einsam"|1 = "Immer" bis 5 = "Nie"|

Wir wir sehen, sind einige Items invertiert formuliert. W√ºrden wir daraus, eine Skala bilden bspw. **Disstress**, k√∂nnten wir mit dem `mutate()`Befehl, keine ad√§quate Skala bilden.

Wir m√ºssen also entscheiden, was nun **hohe Werte und was niedrige Werte** darstellen sollen. Damit es intuitiver ist, wollen wir nun die **Variablen `hs04`, `hs05` und `hs09`umkodieren**, damit sp√§ter es hoher Wert auf der Skala **"viel Disstress"** darstellen kann.

Doch bevor wir Anfangen, laden wir zun√§chst unseren Datensatz und die Pakte wieder ein, bzw. haben diese schon im Environment!

```{r}
#| echo: true
#| warning: false

#install.packages("labelled", repos = "https://cloud.r-project.org")

library(tidyverse)
library(haven)
library(labelled)

df_csv <- read_csv("assets/data/datensatz_workshop.csv")

df_spss <- read_sav("assets/data/spss_datensatz_workshop.sav")

head(df_csv, 10)
```

Zum besseren Verst√§ndnis verkleinern wir erstmal unseren Datensatz: Erstelle den Datensatz `df_diss` mit nur den Items die wir ben√∂tigen.

:::{.callout-tip collapse="true"}
# L√∂sung

```{r}

df_diss <- df_csv |>
select(hs04,hs05,hs06,hs07,hs09)

head(df_diss, 10)

```

:::

Nun k√∂nnen wir in diesem neuen Datensatz, getrennt von den Rohdaten, √ºben!

:::{.panel-tabset}

# Alternative 1

```{r}
#| echo: true

# jede Variable einzeln und manuell

df_diss$hs04_inv <- 6 - df_diss$hs04

head(df_diss$hs04,10)

head(df_diss$hs04_inv,10)
```
:::{.callout-tip collapse="true"}
# **Hinweis**
Bei der Intertierung, wird...
- der Wert`1` zu  `5`
- der Wert `2` zu `4`
- der Wert `3`bleibt `3`
- der Wert `4` zu `2`
- der Wert `5` zu `1`

Die oben vorgstellte **Alternative 1** basiert auf der Annahme **"maximaler Skalenwert" + 1 - "Skalenwert der Person"**.
:::

# Alternative 2

```{r}
#| echo: true

 df_diss<-df_diss|>
    mutate(hs04_inv = recode(hs04,
                             "1"=5,
                             "2"=4,
                             "3"=3,
                             "4"=2,
                             "5"=1),
           hs05_inv = recode(hs05,
                             "1"=5,
                             "2"=4,
                             "3"=3,
                             "4"=2,
                             "5"=1),
           hs09_inv = recode(hs09,
                            "1"=5,
                            "2"=4,
                            "3"=3,
                            "4"=2,
                            "5"=1),
           )

head(df_diss, 10)           
```

# Alternative 3

```{r}
#| echo: true
#| warning: false
#| eval: false

install.packages("sjmisc")

```
```{r}
#| echo: true
#| warning: false

library(sjmisc)

df_diss <- df_diss|>
            mutate(hs04_inv = rec(hs04, rec = "rev"),
                  hs05_inv = rec(hs05, rec = "rev"),
                  hs09_inv = rec(hs09, rec = "rev")
                  )

head(df_diss, 10)

```
:::{.callout-tip collapse="true"}
# **Hinweis**
Wir haben hier einen Befehl aus einem anderen Paket genutzt. Wie du sehen kannst, sind Pakete auch miteinander kombinierbar!

Hier handelt es sich um den `rec()` Befehl aus dem Paket **sjmisc**.
:::
:::



## Umkodieren von Gruppen und Faktoren

Bisher haben wir Variablen umkodiert, die **numerisch skaliert** sind (z. B. Zustimmungsskalen von 1 bis 5).

In der Praxis arbeiten wir jedoch sehr h√§ufig auch mit **kategorialen Variablen**, zum Beispiel:
- Geschlecht  
- Bildungsabschluss  
- Wohnort  
- Erwerbsstatus  

Diese Variablen sind meist als **Faktoren** kodiert oder sollen als solche behandelt werden.

Beim Umkodieren von Faktorvariablen geht es weniger um Rechnen, sondern darum, **Kategorien sinnvoll zusammenzufassen oder neu zu benennen**.

In diesem Abschnitt schauen wir uns daher an, wie wir **Faktorvariablen gezielt umkodieren**, zum Beispiel indem wir:
- mehrere Kategorien zu einer Gruppe zusammenfassen oder  
- neue, besser interpretierbare Gruppen bilden.

___

Wir erstellen nun erneut einen Datensatz und nennen es `df_rec`. Diesmal f√ºgen wir zu unseren Disstress Variablen weitere hinzu. Folgende Variablen sollen hinzugenommen werden:
- `gs01` - Selbsbeschreibung des Wohnorts
- `educ` - Allgemeiner Schulabschluss
- `mstat` - Familienstand
- `im17` bis `im21` - Einstellung zur sozialen Ungleichheit

:::{.callout-important collapse="true"}
# **Beschreibungen der Variablen**

:::{.panel-tabset}
# Wohnort
|**Variable**|**Inhalt**|**Skalierung**|
|----|----|----|
|gs01|"Selbsbeschreibung des Wohnorts"| 1 = Gro√üstadt<br> 2 = Vorort Gro√üstadt<br> 3 = Mittel-/Kleinstadt<br> 4 = l√§ndl. Dorf<br> 5 = Allein stehendes Haus auf dem Land |

# Schulabschluss
|**Variable**|**Inhalt**|**Skalierung**|
|----|----|----|
|educ|"Allgemeiner Schulabschluss"| 1 = Ohne Abschluss<br> 2 = Volks-/Hauptschule<br> 3 = Mittelere Reife<br> 4 = Fachhochschulreife<br> 5 = Hochschulreife<br> 6 = Anderer Abschluss<br> 7 = Noch Sch√ºler*in |

# Familienstand
|**Variable**|**Inhalt**|**Skalierung**|
|----|----|----|
|mstat|"Familienstand"| 1 = Verheiratet (zsm.lebend)<br> 2 = Verheiratet (getrennt)<br> 3 = Verwitwet<br> 4 = Geschieden<br> 5 = Ledig<br> 6 = Lebensp. (zsm.lebend)<br> 7 = Lebensp. (getrennt)<br> 8 = Lebensp. verstorben<br> Lebensp. aufgehoben |

# Soziale Ungleichheit
|**Variable**|**Inhalt**|**Skalierung**|
|----|----|----|
|im17|"Was man im Leben bekommt, h√§ngt gar nicht so sehr von den eigenen Anstrengungen ab, sondern von der Wirtschaftslage, der Lage auf dem Arbeitsmarkt, den Tarifabschl√ºssen und den Sozialleistungen des Staates."| 1 = "Stimme voll zu" bis 4 = "Stimme √ºberhaupt nicht zu"|
|im18|"Das Einkommen sollte sich nicht allein nach der Leistung des Einzelnen richten. Vielmehr sollte jeder das haben, was er mit seiner Familie f√ºr ein anst√§ndiges Leben braucht."| 1 = "Stimme voll zu" bis 4 = "Stimme √ºberhaupt nicht zu"|
|im19|"Nur wenn die Unterschiede im Einkommen und im sozialen Ansehen gro√ü genug sind, gibt es auch einen Anreiz f√ºr pers√∂nliche Leistungen."|1 = "Stimme voll zu" bis 4 = "Stimme √ºberhaupt nicht zu"|
|im20|"Die Rangunterschiede zwischen den Menschen sind akzeptabel, weil sie im Wesentlichen ausdr√ºcken, was man aus den Chancen, die man hatte, gemacht hat."| 1 = "Stimme voll zu" bis 4 = "Stimme √ºberhaupt nicht zu"|
|im21|"Ich finde die sozialen Unterschiede in unserem Land im Gro√üen und Ganzen gerecht."|1 = "Stimme voll zu" bis 4 = "Stimme √ºberhaupt nicht zu"|

:::
:::

:::{.callout-tip collapse="true"}
# L√∂sung
```{r}
#| echo: true
#| warning: false

library(tidyverse)

df_rec<-df_csv|>
  select(gs01,educ,mstat,
         hs04,hs05,hs06,hs07,hs09,
         im17,im18,im19,im20,im21)

head(df_rec, 10)
```
:::

Nun schauen wir uns die Umkodierung von Faktoren am Beispiel des Schulabschlusses an:

:::{.panel-tabset}
# Alternative 1
```{r}

df_rec <- df_rec |>
  mutate(
    wohnort = recode(
      gs01,
      "1"= 1,
      "2" = 1,
      "3" = 1,
      "4" = 2,
      "5" = 2
    ))

head(df_rec, 10)

```
:::{.callout-note collapse="true"}
# Beschreibung
Wir haben nun hier aus f√ºnf Gruppen zwei Gruppen gemacht. Wir unterscheiden nun zwischen **1 = Urban** und **2 = Rural**.
:::

# Alternative 2
```{r}

df_rec <- df_rec |>
  mutate(
    wohnort2 = factor(
      wohnort,
      levels = c(1, 2),
      labels = c("Urban", "Rural")
    )
  )

head(df_rec,10)

```
::: {.callout-note collapse="true"}
# Beschreibung
Wir haben hier die zuvor erstellten Gruppen (`1` und `2`) nun als **Faktor mit Labeln** gemacht.
:::

# Alternative 3
```{r}

df_rec <- df_rec |>
  mutate(
    wohnort3 = recode(
      gs01,
      "1" = 1,
      "2" = 1,
      "3" = 1,
      "4" = 2,
      "5" = 2
    ) |> factor(labels = c("Urban", "Rural"))
  )

head(df_rec, 10)

```
:::{.callout-note collapse="true"}
# Beschreibung
Hier haben wir es in einem Schritt getan.
:::

# Alternative 4

```{r}

df_rec <- df_rec |>
  mutate(
    wohnort4 = recode(
      gs01,
      "1" = "Urban",
      "2" = "Urban",
      "3" = "Urban",
      "4" = "Rural",
      "5" = "Rural"
    ) |> factor(levels = c("Urban", "Rural"))
  )

head(df_rec, 10)

```
:::{.callout-note collapse="true"}
# Beschreibung
Hier haben wir erst "gelabled" und dann Levels hinzugef√ºgt.
:::
:::

## √úbung

Schaut euch die Variablen im neuen Datensatz `df_rec` an. Eure Aufgabe ist es nun neue Variablen zu erstellen, die sinnvoll sind und die wir dann weiter nutzen werden.

1. Erstellt eine neue Variable von `educ` (nennt diese `abschluss`) die vierstufig ist (niedriger, mittlere, hoher und anderer)
2. Erstellt einen Skalenwert f√ºr Disstress und Soziale Unterst√ºtzung. Achtet darauf, dass der Summenwert sinnvol interpretierbar ist.

:::{.callout-tip collapse="true"}
# Tipp

- Schaut euch das Codebuch genauer an, um die Variablen besser zu verstehen.
- Guckt euch nochmal die Skalierung der Skalenitems an!
:::

::: {.callout-tip collapse="true"}
# **L√∂sung**

:::{.panel-tabset}

# Abschluss

```{r}

df_rec <- df_rec |>
  mutate(
    abschluss = recode(
      educ,
      "1" = 1,
      "2" = 1,
      "3" = 2,
      "4" = 3,
      "5" = 3,
      "6" = 4,
      "7" = 1
    ) |> factor(labels = c("Niedriger", "Mittlerer", "Hoher", "Anderer"))
  )

df_rec |>
  select(educ, abschluss) |>
  head(10)


```

# Disstress

```{r}
#| echo: true
#| waring: false

library(sjmisc)

df_rec<-df_rec|>
  mutate(
    hs04_r = rec(hs04, rec = "rev"),
    hs05_r = rec(hs05, rec = "rev"),
    hs09_r = rec(hs09, rec = "rev"),
    disstress = hs04_r + hs05_r + hs06 + hs07+ hs09_r
  )

df_rec |>
  select(hs04, hs04_r, hs05, hs05_r, hs06, hs07, hs09, hs09_r, disstress)|>
  head(10)

```

# Soziale Ungleichheit

```{r}
#| echo: true
#| warning: false

df_rec<-df_rec|>
  mutate(
    im17_r = 5 - im17,
    im18_r = 5 - im18,
    im19_r = 5 - im19,
    im20_r = 5 - im20,
    im21_r = 5 - im21,
    soz.u = rowSums(cbind(im17_r,im18_r,im19_r,im20_r,im21_r))
  )

df_rec |>
  select(im17:im21, im17_r:im21_r, soz.u) |>
  head(10)

```

# Alles in einem Schritt

```{r}
#| echo: true
#| warning: false

df_rec<-df_rec|>
  mutate(
    abschluss = recode(
      educ,
      "1" = 1,
      "2" = 1,
      "3" = 2,
      "4" = 3,
      "5" = 3,
      "6" = 4,
      "7" = 1
    ) |> factor(labels = c("Niedriger", "Mittlerer", "Hoher", "Anderer")),
    hs04_r = rec(hs04, rec = "rev"),
    hs05_r = rec(hs05, rec = "rev"),
    hs09_r = rec(hs09, rec = "rev"),
    distress = hs04_r + hs05_r + hs06 + hs07+ hs09_r,
    im17_r = 5 - im17,
    im18_r = 5 - im18,
    im19_r = 5 - im19,
    im20_r = 5 - im20,
    im21_r = 5 - im21,
    soz.u = rowSums(cbind(im17_r,im18_r,im19_r,im20_r,im21_r))
  )

df_rec |>
  select(abschluss, disstress, soz.u) |>
  head(10)

```
:::
:::

___

# Joins ‚Äì Datens√§tze zusammenf√ºhren

In der Praxis liegen Informationen h√§ufig **nicht in einem einzigen Datensatz** vor. Stattdessen gibt es mehrere Tabellen, die sich auf **dieselben F√§lle** beziehen, z. B.:

- ein Datensatz mit **Befragungsdaten**
- ein weiterer mit **Regionalinformationen**
- oder zus√§tzliche **Kontextvariablen**

Um diese Informationen gemeinsam auswerten zu k√∂nnen, m√ºssen wir die Datens√§tze **zusammenf√ºhren**.  
Genau daf√ºr nutzen wir sogenannte **Joins**.

::: callout-tip
# Grundidee von Joins

Ein **Join** verbindet zwei Datens√§tze √ºber eine **gemeinsame Variable**  
(z. B. eine Personen-ID oder Fallnummer).

üëâ Voraussetzung:  
Beide Datens√§tze enthalten **mindestens eine gemeinsame Schl√ºsselvariable**.
:::

In `dplyr` gibt es verschiedene Join-Typen, die sich darin unterscheiden, **welche F√§lle im Ergebnis erhalten bleiben**.

:::{.callout-note collapse="true"}
# Die Join-Typen
- **left_join()** ‚Üí linker Datensatz bestimmt  
- **right_join()** ‚Üí rechter Datensatz bestimmt  
- **inner_join()** ‚Üí nur √úberschneidung  
- **full_join()** ‚Üí alles von beiden  
:::

Wir schauen uns nun den am **h√§ufigsten** verwendeten Join-Befehl an: `left_join()`. Daf√ºr schauen wir uns nun den Befehl im Detail an.

:::{.callout-note}
# left_join()

left_join(x, y, by = "id")

- x ‚Üí **linker Datensatz**
- y ‚Üí **rechter Datensatz**
- by ‚Üí **Schl√ºsselvariable (hier "id")**
:::

Doch bevor wir nun Datens√§tze zusammenf√ºhren, brauchen wir erstmal einen zweiten Datensatz.

‚û°Ô∏è **[Datensatz f√ºr Kinderarmut und Altersarmut nach Bundesl√§ndern](../ws1/assets/data/armutdaten.csv)**

Wir laden nun den neuen Datensatz in unser Environment.

```{r}
#| echo: true
#| warning: false

df_armut <- read_csv("assets/data/armutdaten.csv")

head(df_armut,10)

```

Nun schauen wir, ob wir eine Schl√ºsselvariable erkennen k√∂nnen. Die Variable `kzf` was die Kennziffer des **Bundeslandes** darstellt, k√∂nnte in Frage kommen. Welche √§hnliche Variable haben wir in unserem **ersten Datensatz**?

:::{.callout-note collapse="true"}
# **Hinweis**
Die Variable `land` sieht doch vielversprechend aus, oder?

```{r}
#| echo: true
#| warning: false

df_spss |>
  select(land) |>
  head(10)

```
:::

Wir gucken uns die Kodierung im **Codebuch** an. Wir m√ºssen vorher die Variable umstrukturieren. Erstelle in unserem **Datensatz** eine neue Variable mit dem namen `kzf`.

:::{.callout-tip collapse="true"}
# **L√∂sung**

```{r}
#| echo: true
#| warning: false

df_spss <- df_spss |>
  mutate(kzf = rec(land,rec="
                   10 = 1;
                   20 = 2;
                   30 = 3;
                   40 = 4;
                   50 = 5;
                   60 = 6;
                   70 = 7;
                   80 = 8;
                   90 = 9;
                   100 = 10;
                   111 = 11;
                   112 = 11;
                   120 = 12;
                   130 = 13;
                   140 = 14;
                   150 = 15;
                   160 = 16"))

df_spss |>
  select(kzf) |>
  head(10)

```
:::

Wir haben nun die **Schl√ºsselvariable** erstellt und finden sie in beiden **Datens√§tzen**.

Bevor wir **die Datens√§tze zusammenf√ºhre**, checken wir nochmal, ob in beiden Datens√§tzen die **Schl√ºsselvariable** vorhanden ist.

```{r}
#| echo: true
#| warning: false

intersect(names(df_spss), names(df_armut))

```

Nun f√ºhren wir die **beiden Datens√§tze** zusammen.

```{r}
#| echo: true
#| warning: false

df_spss_armut <- left_join(df_spss, df_armut, by = "kzf")

df_spss_armut |>
  select(66:70) |>
  head(10)

```

:::{.callout-note}
# **Hinweis**

Bei `select(66:70)` w√§hle ich die Spalten **66 bis 70** in meinem neuen **Datensatz** aus.
:::

## √úbung

Erstellt erneut euren Datensatz aus der letzten Aufgabe und speichert ihn diesmal unter dem Namen **`df_rec2`**. Achtet darauf, dass ihr **eine eindeutige Schl√ºsselvariable** mit√ºbernehmt.

F√ºhrt anschlie√üend **dieselben Umkodierungen** durch wie zuvor bei `df_rec`.

Zum Schluss **f√ºgt ihr den Hauptdatensatz und `df_rec2` zu einem neuen Datensatz** mit dem Namen **`df_analyse`** zusammen.

:::{.callout-tip}
# **Tipp**
**Codebuch** üòâ
:::

:::{.callout-tip collapse="true"}
# **L√∂sung**

```{r}
#| echo: true
#| warning: false

# Erstellen von df_rec2

df_rec2<-df_csv|>
  select(respid,gs01,educ,mstat,
         hs04,hs05,hs06,hs07,hs09,
         im17,im18,im19,im20,im21)

head(df_rec2, 10)

# Umkodieren und Summenwerte erstellen

df_rec2 <-df_rec2|>
  mutate(
    wohnort = recode(gs01,
      "1" = 1,
      "2" = 1,
      "3" = 1,
      "4" = 2,
      "5" = 2
    ) |> factor(labels = c("Urban", "Rural")),
    abschluss = recode(
      educ,
      "1" = 1,
      "2" = 1,
      "3" = 2,
      "4" = 3,
      "5" = 3,
      "6" = 4,
      "7" = 1
    ) |> factor(labels = c("Niedriger", "Mittlerer", "Hoher", "Anderer")),
    hs04_r = rec(hs04, rec = "rev"),
    hs05_r = rec(hs05, rec = "rev"),
    hs09_r = rec(hs09, rec = "rev"),
    distress = hs04_r + hs05_r + hs06 + hs07+ hs09_r,
    im17_r = 5 - im17,
    im18_r = 5 - im18,
    im19_r = 5 - im19,
    im20_r = 5 - im20,
    im21_r = 5 - im21,
    soz.u = rowSums(cbind(im17_r,im18_r,im19_r,im20_r,im21_r))
  )

df_rec2 |>
  select(15:26) |>
  head(10)

# Neuer Datensatz df_analyse

df_analyse <- left_join(df_csv, df_rec2, by="respid")

df_analyse |>
  select(81:91) |>
  head(10)
```
:::{.callout-tip collapse="true"}
# **Tip**
F√ºr eine saubere L√∂sung ohne Duplikate:
```{r}
#| echo: true
#| warning: false

dupl_vars <- setdiff(names(df_rec2), names(df_csv))

df_analyse <- df_csv |>
  left_join(df_rec2 |> select(respid, all_of(dupl_vars)), by = "respid")
```
:::

:::
:::{.callout-important collapse="true"}
# **Merkhilfe der Join-Befehle**

### `left_join()`

Der **linke Datensatz** ist die Basis.

- **alle F√§lle** aus dem linken Datensatz bleiben erhalten  
- passende Informationen aus dem rechten Datensatz werden erg√§nzt  
- nicht gefundene Werte werden als `NA` erg√§nzt  

üëâ **Der am h√§ufigsten verwendete Join** in der Praxis.

### `right_join()`

Der **rechte Datensatz** ist die Basis.

- **alle F√§lle** aus dem rechten Datensatz bleiben erhalten  
- passende Informationen aus dem linken Datensatz werden erg√§nzt  
- nicht gefundene Werte werden als `NA` erg√§nzt  

üëâ Funktional das Gegenst√ºck zu `left_join()`.

### `inner_join()`

Es bleiben **nur die gemeinsamen F√§lle** erhalten.

- F√§lle kommen **nur dann** ins Ergebnis, wenn sie **in beiden Datens√§tzen** vorkommen  
- alle anderen F√§lle werden verworfen  

üëâ Strenger Join ‚Äì gut f√ºr saubere √úberschneidungen.

### `full_join()`

Alle F√§lle aus **beiden Datens√§tzen** bleiben erhalten.

- alle F√§lle aus links **und** rechts  
- wo es keine Entsprechung gibt ‚Üí `NA`  

üëâ Maximale Information, aber oft viele fehlende Werte.

:::

___

# Fehlende Werte (NA)


Nachdem wir Datens√§tze **umkodiert** und **zusammengef√ºhrt** haben, kommen wir zu einem Thema, das in der Praxis **immer** eine Rolle spielt:

üëâ **fehlende Werte (`NA`)**

Fehlende Werte entstehen zum Beispiel, wenn:
- Fragen *nicht* beantwortet wurden  
- bestimmte Fragen nur f√ºr *Teilgruppen* gestellt wurden  
- Datens√§tze zusammengef√ºhrt werden  
- Filter oder Umkodierungen durchgef√ºhrt wurden

::: callout-tip
# **Wichtig**
Fehlende Werte sind **kein Fehler**, sondern ein **normaler Bestandteil realer Daten**.

Wichtig ist, zu verstehen,
- **wo** sie auftreten,
- **wie viele** es sind und
- **wie R mit ihnen umgeht**.
:::

## Was ist `NA`?

In R steht `NA` f√ºr **Not Available** ‚Äì also *fehlender Wert*.

- `NA` ist **keine** 0  
- `NA` ist **kein** leerer Text  
- `NA` bedeutet: ***Es liegt kein Wert vor***

R behandelt `NA` **sehr strikt** ‚Äì und das ist auch gut so.

## Fehlende Werte identifizieren

Bevor wir mit Berechnungen arbeiten, sollten wir immer pr√ºfen, **ob und wo fehlende Werte** vorkommen. Daf√ºr erstellen wir aus unserem **Analysedatensatz `df_analyse`** einen kleineren handlicheren Datensatz mit den Variablen die wir f√ºr unsere Analysen wirklich ben√∂tigen und nennen es `df_analyse2`.

respid,gs01,educ,mstat

Nehme folgende Variablen mit rein:
- `respid`
- `wohnort`
- `isced97`
- `work`
- `dw15`
- `mstat`
- `hhincc`
- `disstress` und dazugeh√∂rigen Variablen
- `soz.u` und dazugeh√∂rigen Variablen

:::{.callout-tip collapse="true"}
# **L√∂sung**
```{r}
#| echo: true
#| warning: false

df_analyse2 <- df_analyse |>
  select(respid,age,sex,wohnort,isced97,work,dw15,
         mstat,hhincc,hs04_r,hs06,hs07,hs05_r,hs09_r,distress,
         im17_r,im18_r,im19_r,im20_r,im21_r,soz.u)

df_analyse2 |>
  head(10)
```
:::

:::{.callout-important collapse="true"}
# **Hinweis**
- Schaut im **Codebuch** nach, was die Variablen bedeuten.
- Achtet darauf, dass ihr die richtigen **Variablennamen** nehmt!
:::

Wir schauen nun unseren Datensatz an:

:::{.panel-tabset}

# Base R
```{r}
#| echo: true
#| warning: false
#| results: false

is.na(df_analyse2)

```
:::{.callout-caution}
# **Achtung**

Sehr **un√ºbersichtlich**, da R hier f√ºr **jede Zeile und jeder Variable** einen logischen Vektor mit `TRUE`oder `FALSE` erstellt.
:::

# **Package `naniar`**
```{r}
#| echo: true
#| warning: false

install.packages("naniar", repos="https://cloud.r-project.org")

library(naniar)

any_na(df_analyse2)
```
:::{.callout-caution}
# **Hinweis**
Mit diesem Befehl, bekommen wir eine schnelle R√ºckmeldung, **ob** unser Datensatz fehlende Werte hat.
:::
:::

### Einzelne Variable pr√ºfen

:::{.panel-tabset}

# Base R
```{r}
#| echo: true
#| warning: false
#| results: false

is.na(df_analyse2$age)

```
:::{.callout-caution}
# **Achtung**

Sehr **un√ºbersichtlich**, da R hier f√ºr **jede Zeile einen logischen Vektor mit `TRUE`oder `FALSE` erstellt.
:::

# **Package `naniar`**
```{r}
#| echo: true
#| warning: false


any_na(df_analyse2$age)

```
:::{.callout-caution}
# **Hinweis**
Mit diesem Befehl, bekommen wir eine schnelle R√ºckmeldung, **ob** in er spezifischen Variable fehlende Werte hat.
:::
:::

Um herauszufinden, **wie viele fehlende Werte** die Variable hat, gehen wir wie folgt vor:

:::{.panel-tabset}

# Base R
```{r}
#| echo: true
#| warning: false

sum(is.na(df_analyse2$age))

```

# **Package `naniar`**
```{r}
#| echo: true
#| warning: false


n_miss(df_analyse2$age)

```

:::

### √úberblick mehrer Variablen

Wir k√∂nnen auch **mehrere spezifische** Variablen anschauen:

:::{.panel-tabset}
# Base R

```{r}
df_analyse2 |>
  summarise(
    across(
      c(distress, soz.u),
      ~ sum(is.na(.))
    )
  )
```
::: callout-note
Hier sehen wir auf einen Blick, wie viele fehlende Werte pro Variable existieren.
:::

# √úberblick (grafisch)

```{r}
#| echo: true
#| warning: false

gg_miss_var(df_analyse2)


```
::: callout-note
Hier sehen wir auf einen Blick, wie viele fehlende Werte pro Variable im **gesamten Datensatz** sind.
:::
:::

## Was passiert bei Berechnungen mit `NA`?

Ein h√§ufiger Stolperstein ist der Umgang mit fehlenden Werten (`NA`) bei Berechnungen.

üëâ Schon ein einziges `NA` reicht aus, damit das gesamte Ergebnis `NA` wird.

```{r}
#| echo: true
#| warning: false


rowSums(cbind(1,5,8,10,NA,20,12,13,NA))


1+5+8+10+NA+20+12+13+NA

```

### Warum ist das so?
R kann nicht erraten, wie mit fehlenden Werten umgegangen werden soll:
- Soll das NA ignoriert werden?
- Soll das Ergebnis trotzdem berechnet werden?
- Oder ist das Ergebnis nicht sinnvoll interpretierbar?

Ohne eine klare Anweisung entscheidet sich R f√ºr die **sichere Variante**
und gibt `NA` zur√ºck.

Das gilt f√ºr viele Funktionen, zum Beispiel:
- `sum()`
- `mean()`
- `rowSums()`
- `rowMeans()`

üëâ Wichtig: Wenn fehlende Werte ignoriert werden sollen, muss man das **explizit angeben**.

```{r}
#| echo: true
#| warning: false

rowSums(cbind(1,5,8,10,NA,20,12,13,NA), na.rm = TRUE)

```
:::{.callout-important}
# **Was bedeutet `na.rm`?**

`na.rm = TRUE` bedeutet:  
**fehlende Werte (`NA`) werden bei der Berechnung ignoriert**.
:::

`na.rm = TRUE` entfernt `NA`-Werte aus der Berechnung, damit Summen trotzdem berechnet werden k√∂nnen.

```{r}
#| echo: true
#| warning: false

rowSums(cbind(1,5,8,10,NA,20,12,13,NA), na.rm = TRUE)

1+5+8+10+20+12+13

```

Wir wissen, dass wir auf einigen Skalen, die wir gebildet haben, viele Missings haben.

```{r}
#| echo: true
#| warning: false

gg_miss_var(df_analyse2)

```

Wir schauen uns das mal genauer an:
```{r}
#| echo: true
#| warning: false

df_analyse2 <- df_analyse2 |>
  mutate(
    soz.u_na = rowSums(cbind(im17_r, im18_r, im19_r, im20_r, im21_r)),
    soz.u_rmt = rowSums(
      cbind(im17_r, im18_r, im19_r, im20_r, im21_r),
      na.rm = TRUE)
  )

df_analyse2 |>
  select(soz.u_na, soz.u_rmt) |>
  gg_miss_var()

```

:::{.callout-warning}
# **Achtung**

`na.rm = TRUE` bedeutet nicht automatisch ‚Äûbesser‚Äú.

Wenn sehr viele Items fehlen, kann ein **Skalenwert inhaltlich verzerrt** sein!
:::

### Wann ist na.rm = TRUE sinnvoll?

- wenn nur wenige Werte fehlen
- wenn ein Skalenwert auch mit 1‚Äì2 fehlenden Items sinnvoll ist
- f√ºr erste Auswertungen und Exploration

## Wie mit fehlenden Werten umgehen?

In der empirischen Forschung gibt es **verschiedene Strategien**, um mit fehlenden Werten umzugehen.  
Welche sinnvoll ist, h√§ngt unter anderem ab von:
- der Anzahl der fehlenden Werte  
- dem Datentyp (Item, Skala, Hintergrundvariable)  
- der Fragestellung der Analyse  

M√∂gliche Ans√§tze sind zum Beispiel:
- fehlende Werte **ignorieren** (`na.rm = TRUE`)
- F√§lle mit fehlenden Werten **ausschlie√üen**
- fehlende Werte **sch√§tzen oder imputieren** (z. B. Mittelwert, multiple Imputation)

üëâ **Wichtig:**  
Diese Entscheidungen haben **inhaltliche Konsequenzen** und sollten immer bewusst getroffen werden.

### Fokus im Workshop

In diesem Workshop konzentrieren wir uns bewusst auf einen **einfachen und transparenten Umgang** mit fehlenden Werten:

üëâ **F√§lle mit fehlenden Werten werden ausgeschlossen**, wenn sie f√ºr die jeweilige Analyse nicht sinnvoll nutzbar sind.

Warum?
- leicht nachvollziehbar  
- gut geeignet f√ºr den Einstieg 
- h√§ufig ausreichend bei gro√üen Stichproben  

Komplexere Verfahren wie **Imputation** sind wichtig, gehen aber √ºber den Rahmen dieses Workshops hinaus. Es lohnt sich aber hier **methodisch** einzuarbeiten!

üëâ **Multiple Imputation**

## Fehlende Werte entfernen

Wie oben angesprochen, entfernen wir bei **ausreichender Datengrundlage** die Personen, die einen fehlende Werte auf die uns wichtigen Variablen haben.

### Ganze Zeilen entfernen (`drop_na()`)

Mit `drop_na()` entfernen wir **alle Zeilen**,  
in denen mindestens ein `NA` in den angegebenen Variablen vorkommt.

```{r}
#| echo: true
#| warning: false

df_clean <- df_analyse2 |>
  drop_na(soz.u_na)

df_clean |>
  dim()

  df_analyse2 |>
  dim()
```

üëâ Ergebnis: Nur F√§lle ohne fehlende Werte in `soz.u` bleiben erhalten.

:::{.callout-tip collapse="true"}
# Tipp
Um zu schauen, wie viele Personen damit ausgeschlossen wurden, kann man folgendes machen:

```{r}
#| echo: true
#| warning: false

nrow(df_analyse2) - nrow(df_clean)

```
:::

## √úbung

Erstelle einen Datensatz `df_clean`, welcher frei von `NA's` ist f√ºr die Variablen `distress` und `soz.u`. 

- Wie viele Beobachtungen werden final ausgeschlossen?

:::{.callout-tip collapse="true"}
# **L√∂sung**

```{r}
#| echo: true
#| warning: false

df_analyse2 <- df_analyse2 |>
  mutate(
    distress_na = rowSums(cbind(hs04_r,hs06,hs07,hs05_r,hs09_r)),
    distress_rmt = rowSums(
      cbind(hs04_r,hs06,hs07,hs05_r,hs09_r),
      na.rm = TRUE)
  )

df_clean <- df_analyse2 |>
  drop_na(distress_na, soz.u_na)

nrow(df_analyse2) - nrow(df_clean) 

```
:::

:::{.callout-tip}
# **Tipps**

:::{.panel-tabset}
# **Gute Praxis**

Nach dem Entfernen von `NA` immer pr√ºfen:

- Wie viele F√§lle sind √ºbrig?
- Ist die Fallzahl noch ausreichend?
- Betrifft das Entfernen bestimmte Gruppen st√§rker als andere?

# **Merksatz**

Es gibt keinen automatisch richtigen Umgang mit fehlenden Werten. Wichtig ist,

- bewusst zu entscheiden,
- transparent zu dokumentieren,
- und die Konsequenzen zu kennen.
:::
:::

# Recap Workshop

Bevor wir ins **Mini-Projekt** starten, fassen wir kurz zusammen, was wir an **Tag 1** und **Tag 2** gemacht haben.

:::{.callout-note}
# **RECAPS**

:::{.panel-tabset}
# **Recap ‚Äì Tag 1 (Grundlagen)**

- **R vs. RStudio**: Was ist die Sprache, was ist die Oberfl√§che?
- **RStudio verstehen**: Script, Console, Environment, Files/Plots/Help
- **Projekte anlegen**: Warum Projekte wichtig sind (Pfade, Ordnung, Reproduzierbarkeit)
- **R-Skripte nutzen**: Code speichern, wiederverwenden, nachvollziehbar arbeiten
- **Objekte & Zuweisung**: `<-`, Vektoren mit `c()`, Werte speichern
- **Funktionen**: `mean()`, `sd()`, `sum()`, `length()` usw. + Kombinationen
- **Datentypen & Strukturen**: numeric/character/factor und Vektor vs. Data Frame
- **Datensatzstruktur**: Zugriff auf Variablen mit `$` und erste Kennwerte
- **Pakete**: `install.packages()` vs. `library()` (tidyverse, haven, psych)
- **Datenimport**: CSV und SPSS (`read_csv()`, `read_sav()`)
- **Plausibilit√§tscheck**: `summary()` und `glimpse()`
- **Datenaufbereitung mit dplyr**: `select()`, `filter()`, `mutate()` + neue Objekte
- **Pipes** (`|>`): Schritte lesbar als Workflow ‚Äûhintereinander‚Äú schreiben

# **Recap ‚Äì Tag 2 (Datenaufbereitung)**

- **Umkodieren**:
  - invertierte Items (Skalen in gleiche Richtung bringen)
  - Gruppen/Faktoren zusammenfassen (z. B. Wohnort ‚Üí Urban/Rural)
  - Labels / Faktoren erstellen (Interpretation verbessern)
- **Skalenbildung**:
  - Summenwerte erstellen (z. B. `rowSums()` f√ºr mehrere Items)
  - Hinweis: Richtung & Interpretation vorher festlegen
- **Joins (Datens√§tze zusammenf√ºhren)**:
  - Schl√ºsselvariablen identifizieren/erstellen
  - `left_join()` als Standardfall, plus √úberblick: right/inner/full
- **Fehlende Werte (NA)**:
  - NA erkennen und z√§hlen (`any_na()`, `n_miss()`, `gg_miss_var()`)
  - verstehen, was NA bei Berechnungen macht
  - `na.rm = TRUE` als explizite Anweisung zum Ignorieren
  - `drop_na()` als einfacher Workflow-Schritt f√ºr ‚Äûsaubere‚Äú Analysedaten
:::
:::

## **Workflow**

Ziel ist ein **gut dokumentierter und jederzeit nachvollziehbarer Analyse-Workflow**:  
Jemand anderes (oder du in 3 Monaten) soll verstehen, **was** du gemacht hast, **warum** du es gemacht hast und **wie** du zu deinen Ergebnissen kommst.

:::{.panel-tabset}

# Projektstruktur

Eine m√∂gliche Struktur:

- `projektname/`  
  - `data/`  *(Rohdaten & ggf. bereinigte Daten)*  
  - `scripts/`  *(alle R-Skripte)*  
  - `output/`  *(Tabellen, Abbildungen, Reports)*  
  - `projektname.Rproj`

# Skripte sinnvoll gliedern

Statt ein langes Skript:

- `01_import.R`  *(Daten laden, erste Checks)*  
- `02_cleaning.R`  *(Umkodieren, Skalen, Missing neue Variablen)*  
- `03_analysis.R`  *(Modelle, Tests, Kennwerte)*  
- `04_plots.R`  *(Visualisierungen, Export)*  

So kannst du jeden Schritt einzeln ausf√ºhren, testen und bei Fehlern gezielt zur√ºckspringen.

# Kommentare nutzen

Kommentiere kurz, **was** passiert und **warum**:

- Was wird hier gemacht?  
- Welche Annahme steckt dahinter?  
- Welche Variablen/Skalen sind wichtig?

Beispiel:

```{r}
# Invertiere hs04/hs05/hs09, damit hohe Werte = mehr Distress bedeuten
# Skala: 1‚Äì5, deshalb: 6 - Wert
```
:::

## **Exkurs: Datensatz Speichern**

Nach der Datenaufbereitung oder Analyse ist es sinnvoll, **Zwischenergebnisse zu speichern** (z. B. bereinigte Datens√§tze oder finale Analyse-Daten).

So kannst du sp√§ter direkt weiterarbeiten, ohne alle Schritte erneut ausf√ºhren zu m√ºssen.

:::{.panel-tabset}
# CSV

- plattformunabh√§ngig
- gut f√ºr Weitergabe und Dokumentation

```{r}
#| echo: true
#| warning: false

write_csv(df_clean, file = "assets/data/output/Datensatz_clean.csv")

```

# SPSS

- praktisch f√ºr Zusammenarbeit mit SPSS-Nutzer:innen
- Variablenlabels bleiben erhalten

```{r}
#| echo: true
#| warning: false

write_sav(df_clean, path = "assets/data/output/spss_Datensatz_clean.sav")

```
:::

___

# Mini-Projekt

Wir kombinieren alles: Import ‚Üí Check ‚Üí Missing ‚Üí Recodes ‚Üí Join ‚Üí Export.

___

[‚¨ÖÔ∏è Zur√ºck zu Tag 1](day1.qmd){.btn .btn-primary}